{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SAMAROHA CHATTERJEE\n",
        "## ROLL: MDS202342"
      ],
      "metadata": {
        "id": "_7zZ1nCeWo0c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQtJB4ngRfHG",
        "outputId": "f896a856-1a57-4bbe-8745-feec19635f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# General Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eI_ykILfWm2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths in Google Drive\n",
        "drive_path = \"/content/drive/MyDrive/AppliedMachineLearning/Assignment_1\"\n",
        "train_path = f\"{drive_path}/train.csv\"\n",
        "val_path = f\"{drive_path}/validation.csv\"\n",
        "test_path = f\"{drive_path}/test.csv\"\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(train_path)\n",
        "val_df = pd.read_csv(val_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# Verify data\n",
        "print(train_df.head())\n",
        "print(f\"‚úÖ Data Loaded: Train ({len(train_df)}), Validation ({len(val_df)}), Test ({len(test_df)})\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SNGR_MuRju9",
        "outputId": "5c416a9f-c2e1-4eff-c978-6c9e755d60b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                            message\n",
            "0      0                                          guy close\n",
            "1      0  please come imin towndontmatter urgoin outlrju...\n",
            "2      0                          ok ksry knw sivatats askd\n",
            "3      0                                ill see prolly yeah\n",
            "4      0        ill see swing bit got thing take care firsg\n",
            "‚úÖ Data Loaded: Train (4457), Validation (557), Test (558)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Handle missing values\n",
        "train_df['message'] = train_df['message'].fillna(\"\")\n",
        "val_df['message'] = val_df['message'].fillna(\"\")\n",
        "test_df['message'] = test_df['message'].fillna(\"\")\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)  # Limit to 5000 features\n",
        "\n",
        "# Transform data\n",
        "X_train = vectorizer.fit_transform(train_df['message'])\n",
        "X_val = vectorizer.transform(val_df['message'])\n",
        "X_test = vectorizer.transform(test_df['message'])\n",
        "\n",
        "y_train = train_df['label']\n",
        "y_val = val_df['label']\n",
        "y_test = test_df['label']\n",
        "\n",
        "print(\"‚úÖ Missing values handled and TF-IDF Vectorization Complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUbhPz26Simd",
        "outputId": "30c34271-261f-4e66-ce2d-ce1f4e9be2a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing values handled and TF-IDF Vectorization Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def create_pipeline(model):\n",
        "    \"\"\"\n",
        "    Creates a pipeline with the classifier.\n",
        "    \"\"\"\n",
        "    return Pipeline([\n",
        "        ('clf', model)\n",
        "    ])\n",
        "\n",
        "def train_models(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Trains multiple models and selects the best one based on validation accuracy.\n",
        "    \"\"\"\n",
        "    models = {\n",
        "        \"Naive Bayes\": create_pipeline(MultinomialNB()),\n",
        "        \"Logistic Regression\": create_pipeline(LogisticRegression(max_iter=1000)),\n",
        "        \"SVM\": create_pipeline(SVC(kernel='linear', probability=True))\n",
        "    }\n",
        "\n",
        "    model_scores = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nüîπ Training {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate on train and validation sets\n",
        "        train_acc = accuracy_score(y_train, model.predict(X_train))\n",
        "        val_acc = accuracy_score(y_val, model.predict(X_val))\n",
        "\n",
        "        print(f\"‚úÖ {name} - Train Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "        model_scores[name] = val_acc\n",
        "\n",
        "    # Select Best Model\n",
        "    best_model_name = max(model_scores, key=model_scores.get)\n",
        "    best_model = models[best_model_name]\n",
        "    print(f\"\\nüèÜ Best Model Selected: {best_model_name}\")\n",
        "    return best_model_name, best_model\n",
        "\n",
        "best_model_name, best_model = train_models(X_train, y_train, X_val, y_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54gRf8_WS0ys",
        "outputId": "6390c771-2c1d-4467-b4b3-1c6708b8dd4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Training Naive Bayes...\n",
            "‚úÖ Naive Bayes - Train Accuracy: 0.9800, Validation Accuracy: 0.9659\n",
            "\n",
            "üîπ Training Logistic Regression...\n",
            "‚úÖ Logistic Regression - Train Accuracy: 0.9686, Validation Accuracy: 0.9605\n",
            "\n",
            "üîπ Training SVM...\n",
            "‚úÖ SVM - Train Accuracy: 0.9937, Validation Accuracy: 0.9838\n",
            "\n",
            "üèÜ Best Model Selected: SVM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def fine_tune_hyperparameters(best_model_name, best_model, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Fine-tunes hyperparameters using Grid Search.\n",
        "    \"\"\"\n",
        "    param_grid = {\n",
        "        \"SVM\": {\"clf__C\": [ 0.1, 1, 10]}\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(best_model, param_grid[best_model_name], scoring='accuracy', cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"\\nüîç Best hyperparameters: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "best_model = fine_tune_hyperparameters(best_model_name, best_model, X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1jYw77cTDK0",
        "outputId": "91842a94-3f16-4588-e57f-7ef2d12fc728"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Best hyperparameters: {'clf__C': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the test dataset.\n",
        "    \"\"\"\n",
        "    test_preds = model.predict(X_test)\n",
        "    test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "    print(f\"\\n‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "    print(\"\\nüìä Test Classification Report:\\n\", classification_report(y_test, test_preds))\n",
        "\n",
        "evaluate_model(best_model, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9cVYA5cTVoc",
        "outputId": "8da9bef1-9065-4cac-e8ba-5af0e66a964a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Test Accuracy: 0.9713\n",
            "\n",
            "üìä Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       483\n",
            "           1       0.89      0.89      0.89        75\n",
            "\n",
            "    accuracy                           0.97       558\n",
            "   macro avg       0.94      0.94      0.94       558\n",
            "weighted avg       0.97      0.97      0.97       558\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model\n",
        "model_path = os.path.join(drive_path, \"SVM_model.pkl\")\n",
        "joblib.dump(best_model, model_path)\n",
        "\n",
        "print(f\"\\n‚úÖ Model saved successfully at {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j59iuWaT-8c",
        "outputId": "1f327404-84e5-47bc-de80-9b9ff6125d87"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Model saved successfully at /content/drive/MyDrive/AppliedMachineLearning/Assignment_1/SVM_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üìå SMS Spam Classification: Model Training & Evaluation**\n",
        "\n",
        "### **1Ô∏è‚É£ Objective**\n",
        "The goal of this project was to build a robust **SMS spam classifier** that can distinguish between **ham (non-spam) messages** and **spam messages**. We implemented a **machine learning pipeline** that involved **feature extraction, model training, fine-tuning, and evaluation**.\n",
        "\n",
        "---\n",
        "\n",
        "### **2Ô∏è‚É£ Methodology**\n",
        "The following workflow was followed:\n",
        "\n",
        "1. **Data Loading**  \n",
        "   - Preprocessed and cleaned dataset loaded from Google Drive.\n",
        "   - Train, Validation, and Test splits used for model training and evaluation.\n",
        "\n",
        "2. **Feature Extraction using TF-IDF**  \n",
        "   - We converted SMS text into numerical form using **Term Frequency - Inverse Document Frequency (TF-IDF)**.\n",
        "   - The vocabulary was limited to **5000 features** for efficiency.\n",
        "\n",
        "3. **Model Training & Selection**  \n",
        "   - Three models were trained:  \n",
        "     - **Na√Øve Bayes**  \n",
        "     - **Logistic Regression**  \n",
        "     - **Support Vector Machine (SVM)**\n",
        "   - Model performance was evaluated using **accuracy on the validation set**.\n",
        "\n",
        "| Model  | Train Accuracy | Validation Accuracy |\n",
        "|--------|---------------|---------------------|\n",
        "| **Na√Øve Bayes** | 98.00% | 96.59% |\n",
        "| **Logistic Regression** | 96.86% | 96.05% |\n",
        "| **SVM** | 99.37% | 98.38% |\n",
        "\n",
        "üèÜ **Best Model Selected: Support Vector Machine (SVM)**\n",
        "\n",
        "4. **Hyperparameter Tuning (Grid Search)**  \n",
        "   - Optimized `C` parameter in SVM to find the best-performing setting.\n",
        "   - **Best hyperparameter found:**  \n",
        "     \\[\n",
        "     C = 10\n",
        "     \\]\n",
        "\n",
        "5. **Model Evaluation on Test Set**  \n",
        "   - The **fine-tuned SVM model** was evaluated on the unseen test set.\n",
        "\n",
        "---\n",
        "\n",
        "### **3Ô∏è‚É£ Results & Final Model Performance**\n",
        "#### **üîπ Test Accuracy:**\n",
        "\\[\n",
        "97.13\\%\n",
        "\\]\n",
        "\n",
        "#### **üîπ Classification Report:**\n",
        "| Class  | Precision | Recall | F1-Score | Support |\n",
        "|--------|-----------|--------|----------|---------|\n",
        "| **Ham (0)** | 98% | 98% | 98% | 483 |\n",
        "| **Spam (1)** | 89% | 89% | 89% | 75 |\n",
        "\n",
        "‚úÖ **The model achieves high accuracy, with strong spam detection capabilities.**  \n",
        "üìâ **Possible improvements:** Handling class imbalance using **oversampling techniques (SMOTE)** or **ensemble learning methods**.\n",
        "\n",
        "---\n",
        "\n",
        "### **4Ô∏è‚É£ Model Deployment & Future Work**\n",
        "- The **trained SVM model was saved** for future use:\n",
        "  ```bash\n",
        "  SVM_model.pkl\n"
      ],
      "metadata": {
        "id": "_eXSZQUMT42F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fm1HOQZkT6js"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}