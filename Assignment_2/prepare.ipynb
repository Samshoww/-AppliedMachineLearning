{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv(\"raw_data.csv\")\n",
    "\n",
    "# Split into train (70%), validation (15%), and test (15%)\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=46)\n",
    "validation, test = train_test_split(temp, test_size=0.5, random_state=46)\n",
    "\n",
    "# Save the splits\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "validation.to_csv(\"validation.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "print(\"Data split and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Label', 'Message'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"raw_data.csv\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv:\n",
      "Label\n",
      "ham     3362\n",
      "spam     538\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "validation.csv:\n",
      "Label\n",
      "ham     736\n",
      "spam    100\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test.csv:\n",
      "Label\n",
      "ham     727\n",
      "spam    109\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train.csv\", \"validation.csv\", \"test.csv\"]:\n",
    "    df = pd.read_csv(split)\n",
    "    print(f\"{split}:\")\n",
    "    print(df[\"Label\"].value_counts(), \"\\n\")  # Use \"Label\" instead of \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data re-split and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv(\"raw_data.csv\")\n",
    "\n",
    "# Re-split with a different random seed\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=12000)  # New random seed\n",
    "validation, test = train_test_split(temp, test_size=0.5, random_state=12000)  # New random seed\n",
    "\n",
    "# Save the updated splits\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "validation.to_csv(\"validation.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "print(\"Data re-split and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv:\n",
      "Label\n",
      "ham     3368\n",
      "spam     532\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "validation.csv:\n",
      "Label\n",
      "ham     731\n",
      "spam    105\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test.csv:\n",
      "Label\n",
      "ham     726\n",
      "spam    110\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train.csv\", \"validation.csv\", \"test.csv\"]:\n",
    "    df = pd.read_csv(split)\n",
    "    print(f\"{split}:\")\n",
    "    print(df[\"Label\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv (Previous):\n",
      "Label\n",
      "ham     3362\n",
      "spam     538\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "validation.csv (Previous):\n",
      "Label\n",
      "ham     736\n",
      "spam    100\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test.csv (Previous):\n",
      "Label\n",
      "ham     727\n",
      "spam    109\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train.csv\", \"validation.csv\", \"test.csv\"]:\n",
    "    df = pd.read_csv(split)\n",
    "    print(f\"{split} (Previous):\")\n",
    "    print(df[\"Label\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv (Updated):\n",
      "Label\n",
      "ham     3368\n",
      "spam     532\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "validation.csv (Updated):\n",
      "Label\n",
      "ham     731\n",
      "spam    105\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "test.csv (Updated):\n",
      "Label\n",
      "ham     726\n",
      "spam    110\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train.csv\", \"validation.csv\", \"test.csv\"]:\n",
    "    df = pd.read_csv(split)\n",
    "    print(f\"{split} (Updated):\")\n",
    "    print(df[\"Label\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Data Preparation\n",
    "\n",
    "In this notebook, we performed the following steps to prepare the data for machine learning:\n",
    "\n",
    "### **1. Loading the Raw Data**\n",
    "- The raw dataset (`raw_data.csv`) was loaded using `pandas`.\n",
    "- The dataset contains two columns:\n",
    "  - `Label`: The target variable (e.g., `ham` or `spam`).\n",
    "  - `Message`: The text data (e.g., SMS messages).\n",
    "\n",
    "### **2. Splitting the Data**\n",
    "- The dataset was split into three subsets:\n",
    "  - **Training Set (70%)**: Used to train the machine learning models.\n",
    "  - **Validation Set (15%)**: Used to tune hyperparameters and evaluate model performance during training.\n",
    "  - **Test Set (15%)**: Used to evaluate the final model performance.\n",
    "- The splits were created using `train_test_split` from `scikit-learn` with a fixed random seed (`random_state=46`) for reproducibility.\n",
    "\n",
    "### **3. Saving the Splits**\n",
    "- The training, validation, and test sets were saved as separate CSV files:\n",
    "  - `train.csv`\n",
    "  - `validation.csv`\n",
    "  - `test.csv`\n",
    "\n",
    "### **4. Tracking Data with DVC**\n",
    "- The data files (`train.csv`, `validation.csv`, `test.csv`) were tracked using **DVC (Data Version Control)**.\n",
    "- DVC allows us to version control large data files without storing them in Git.\n",
    "- The following commands were executed in the terminal to track the data:\n",
    "  ```bash\n",
    "  dvc add train.csv validation.csv test.csv\n",
    "  git add train.csv.dvc validation.csv.dvc test.csv.dvc .gitignore\n",
    "  git commit -m \"Track train/validation/test splits with DVC\"\n",
    "  dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating Data Splits with a New Random Seed\n",
    "To ensure robustness, the data was re-split using a different random seed (random_state=12000).\n",
    "\n",
    "The updated splits were saved and tracked with DVC using the following commands:\n",
    "\n",
    "bash\n",
    "Copy\n",
    "dvc add train.csv validation.csv test.csv\n",
    "git add train.csv.dvc validation.csv.dvc test.csv.dvc\n",
    "git commit -m \"Update data split with new random seed (12000)\"\n",
    "dvc push\n",
    "6. Verifying Data Distributions\n",
    "The distribution of the target variable (Label) was checked for each split:\n",
    "\n",
    "Training Set: Distribution of ham and spam messages.\n",
    "\n",
    "Validation Set: Distribution of ham and spam messages.\n",
    "\n",
    "Test Set: Distribution of ham and spam messages.\n",
    "\n",
    "This ensures that the splits are balanced and representative of the original dataset.\n",
    "\n",
    "7. Checking Out Previous Versions\n",
    "To compare the data distributions before and after updating the random seed, the following commands were executed:\n",
    "\n",
    "bash\n",
    "Copy\n",
    "git checkout HEAD~1  # Checkout the previous commit\n",
    "dvc checkout\n",
    "After verifying the previous splits, the updated version was restored using:\n",
    "\n",
    "bash\n",
    "Copy\n",
    "git checkout master  # Checkout the latest commit\n",
    "dvc checkout\n",
    "Key Takeaways\n",
    "The data preparation process ensures that the dataset is ready for machine learning.\n",
    "\n",
    "Using DVC allows us to version control the data and track changes over time.\n",
    "\n",
    "Splitting the data into training, validation, and test sets ensures that the model can be trained, tuned, and evaluated effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
