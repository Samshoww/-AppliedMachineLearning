{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18824edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Ensure model dir exists\n",
    "Path(\"models\").mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e30caaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test sizes: 4457/557/558\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>guy close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>please come imin towndontmatter urgoin outlrju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ok ksry knw sivatats askd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ill see prolly yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ill see swing bit got thing take care firsg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0                                          guy close\n",
       "1      0  please come imin towndontmatter urgoin outlrju...\n",
       "2      0                          ok ksry knw sivatats askd\n",
       "3      0                                ill see prolly yeah\n",
       "4      0        ill see swing bit got thing take care firsg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"./data_splits\")\n",
    "train_df = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "val_df   = pd.read_csv(DATA_DIR / \"validation.csv\")\n",
    "test_df  = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "\n",
    "print(f\"Train/Val/Test sizes: {len(train_df)}/{len(val_df)}/{len(test_df)}\")\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08cefaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (train_df, val_df, test_df):\n",
    "    df['message'] = df['message'].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247fde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate pipelines\n",
    "pipelines = {\n",
    "    \"Naive Bayes\": Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=5000, stop_words=\"english\")),\n",
    "        (\"clf\", MultinomialNB())\n",
    "    ]),\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=5000, stop_words=\"english\")),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "    \"SVM\": Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=5000, stop_words=\"english\")),\n",
    "        (\"clf\", SVC(kernel=\"linear\", probability=True, random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Optional hyperparams (only for SVM here)\n",
    "param_grids = {\n",
    "    \"SVM\": {\n",
    "        \"clf__C\": [0.1, 1, 10]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4cdb90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes          ‚Üí Acc: 0.9641, ROC-AUC: 0.9738\n",
      "Logistic Regression  ‚Üí Acc: 0.9623, ROC-AUC: 0.9755\n",
      "SVM                  ‚Üí Acc: 0.9838, ROC-AUC: 0.9761\n",
      "\n",
      "üèÜ Best on Val: SVM (ROC-AUC=0.9761)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.983842</td>\n",
       "      <td>0.976051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.962298</td>\n",
       "      <td>0.975519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.964093</td>\n",
       "      <td>0.973756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy   roc_auc\n",
       "SVM                  0.983842  0.976051\n",
       "Logistic Regression  0.962298  0.975519\n",
       "Naive Bayes          0.964093  0.973756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train_df['message'], train_df['label']\n",
    "X_val,   y_val   = val_df  ['message'], val_df  ['label']\n",
    "\n",
    "results = {}\n",
    "best_model = None\n",
    "best_name  = None\n",
    "best_auc   = -1\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_val)\n",
    "    probs = pipeline.predict_proba(X_val)[:,1]\n",
    "    acc  = accuracy_score(y_val, preds)\n",
    "    auc  = roc_auc_score(y_val, probs)\n",
    "    results[name] = (acc, auc)\n",
    "    print(f\"{name:20s} ‚Üí Acc: {acc:.4f}, ROC-AUC: {auc:.4f}\")\n",
    "    if auc > best_auc:\n",
    "        best_auc   = auc\n",
    "        best_model = pipeline\n",
    "        best_name  = name\n",
    "\n",
    "print(f\"\\nüèÜ Best on Val: {best_name} (ROC-AUC={best_auc:.4f})\")\n",
    "pd.DataFrame.from_dict(results, orient='index', columns=['accuracy','roc_auc']) \\\n",
    "  .sort_values('roc_auc', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fedf38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparams for SVM‚Ä¶\n",
      "‚Üí Best params: {'clf__C': 1}\n"
     ]
    }
   ],
   "source": [
    "if best_name in param_grids:\n",
    "    print(f\"Tuning hyperparams for {best_name}‚Ä¶\")\n",
    "    gs = GridSearchCV(\n",
    "        best_model,\n",
    "        param_grids[best_name],\n",
    "        cv=5,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_model = gs.best_estimator_\n",
    "    print(f\"‚Üí Best params: {gs.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c4e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9856    0.9917    0.9886       483\n",
      "           1     0.9444    0.9067    0.9252        75\n",
      "\n",
      "    accuracy                         0.9803       558\n",
      "   macro avg     0.9650    0.9492    0.9569       558\n",
      "weighted avg     0.9801    0.9803    0.9801       558\n",
      "\n",
      "Accuracy: 0.9803\n",
      "ROC-AUC:   0.9871\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_df['message'], test_df['label']\n",
    "test_preds = best_model.predict(X_test)\n",
    "test_probs = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"üìä Test Set Performance:\")\n",
    "print(classification_report(y_test, test_preds, digits=4))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, test_preds):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, test_probs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39cf30a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved TF-IDF and SVM classifier in models/\n"
     ]
    }
   ],
   "source": [
    "# Extract vectorizer and classifier\n",
    "vectorizer = best_model.named_steps['tfidf']\n",
    "classifier = best_model.named_steps['clf']\n",
    "\n",
    "joblib.dump(vectorizer, Path(\"models\")/\"tfidf_vectorizer.joblib\")\n",
    "joblib.dump(classifier, Path(\"models\")/f\"clf_{best_name.replace(' ','_')}.joblib\")\n",
    "print(f\"‚úÖ Saved TF-IDF and {best_name} classifier in models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfa86b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Full pipeline saved at: models\\pipeline_SVM.joblib\n"
     ]
    }
   ],
   "source": [
    "# ====== Persist full pipeline for scoring ======\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "pipeline_path = Path(\"models\")/\"pipeline_SVM.joblib\"\n",
    "joblib.dump(best_model, pipeline_path)\n",
    "print(f\"‚úÖ Full pipeline saved at: {pipeline_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c52591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 0.529251082319466\n"
     ]
    }
   ],
   "source": [
    "from score import score\n",
    "p, prop = score(\"Free money\", 0.5)\n",
    "print(p, prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dda78912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 1.59s\u001b[0m\u001b[0m\n",
      "\n",
      "‚úÖ Unit tests passed!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "res = subprocess.run([\"pytest\",\"test_score.py\",\"-q\"], capture_output=True, text=True)\n",
    "print(res.stdout)\n",
    "assert res.returncode == 0\n",
    "print(\"‚úÖ Unit tests passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b94cbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "JSON response: {'prediction': 1, 'propensity': 0.9999960798222837}\n",
      "‚úÖ Smoke test passed\n"
     ]
    }
   ],
   "source": [
    "import subprocess, time, requests\n",
    "\n",
    "# 1) Launch the Flask app in a subprocess\n",
    "proc = subprocess.Popen([\"python\", \"app.py\"])\n",
    "time.sleep(2)  # give it time to start\n",
    "\n",
    "try:\n",
    "    # 2) Send a test request\n",
    "    resp = requests.post(\n",
    "        \"http://127.0.0.1:5000/score\",\n",
    "        json={\"text\": \"Free lottery, click here to claim!\"}\n",
    "    )\n",
    "    print(\"Status code:\", resp.status_code)\n",
    "    print(\"JSON response:\", resp.json())\n",
    "    assert resp.status_code == 200\n",
    "    jr = resp.json()\n",
    "    assert \"prediction\" in jr and \"propensity\" in jr\n",
    "    assert isinstance(jr[\"prediction\"], int)\n",
    "    assert 0.0 <= jr[\"propensity\"] <= 1.0\n",
    "    print(\"‚úÖ Smoke test passed\")\n",
    "finally:\n",
    "    # 3) Tear down the Flask app\n",
    "    proc.terminate()\n",
    "    proc.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59e61c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1\n",
      "[notice] To update, run: C:\\Users\\samar\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install coverage --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df9037ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                     [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 2.13s\u001b[0m\u001b[0m\n",
      "Name            Stmts   Miss  Cover\n",
      "-----------------------------------\n",
      "app.py             15     15     0%\n",
      "score.py            8      5    38%\n",
      "test_flask.py      15      0   100%\n",
      "test_score.py      19      0   100%\n",
      "-----------------------------------\n",
      "TOTAL              57     20    65%\n",
      "\n",
      "‚úÖ coverage.txt created.\n"
     ]
    }
   ],
   "source": [
    "import coverage\n",
    "import pytest\n",
    "\n",
    "# Start coverage\n",
    "cov = coverage.Coverage(source=[\".\"], omit=[\"*/venv/*\", \"*/.venv/*\", \"*/__pycache__/*\"])\n",
    "cov.start()\n",
    "\n",
    "# Run all tests\n",
    "pytest.main([\"-q\", \"--disable-warnings\", \"--maxfail=1\"])\n",
    "\n",
    "# Stop and save\n",
    "cov.stop()\n",
    "cov.save()\n",
    "\n",
    "# Write report to file\n",
    "with open(\"coverage.txt\", \"w\") as f:\n",
    "    cov.report(file=f)\n",
    "\n",
    "# Print summary to screen\n",
    "cov.report()\n",
    "print(\"\\n‚úÖ coverage.txt created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
